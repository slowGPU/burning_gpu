{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from dataset import SliceDataModule, SliceGrappaDataModule\n",
    "from common.utils import save_reconstructions\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "HASH = \"4c7f8191cbce4bc9bb9ffc5fe25e5913\"\n",
    "SAVE_DIR = f\"reconstructions/{HASH}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_cls, ckpt_path: str | Path):\n",
    "    checkpoint = torch.load(ckpt_path)\n",
    "\n",
    "    hparams = checkpoint[\"hyper_parameters\"]\n",
    "    del hparams[\"_class_path\"]\n",
    "    del hparams[\"_instantiator\"]\n",
    "    model = model_cls(**hparams)\n",
    "    model.load_state_dict(torch.load(ckpt_path)[\"state_dict\"])\n",
    "    model = model.cuda()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import VarNetToyRestormerOL as Model\n",
    "\n",
    "best_epoch = 3\n",
    "ckpt_path = f\"mlartifacts/0/{HASH}/artifacts/checkpoints/epoch_{best_epoch}/checkpoint.pth\"\n",
    "model = load_model(Model, ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = SliceDataModule(root=\"/Data\")\n",
    "dm.setup(\"test\")\n",
    "dm.setup(\"predict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructing public leaderboard...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/984 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 984/984 [04:49<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving reconstructions of public leaderboard...\n",
      "Reconstructing private leaderboard...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 984/984 [04:49<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving reconstructions of private leaderboard...\n"
     ]
    }
   ],
   "source": [
    "work = {\"public\": dm.test_dataloader(), \"private\": dm.predict_dataloader()}\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for phase, dataloader in work.items():\n",
    "        reconstructions = defaultdict(dict)\n",
    "        print(f\"Reconstructing {phase} leaderboard...\")\n",
    "\n",
    "        if isinstance(dm, SliceGrappaDataModule):\n",
    "            for mask, kspace, grappa, target, maximum, fnames, slices in tqdm(\n",
    "                dataloader\n",
    "            ):\n",
    "                output = model(\n",
    "                    kspace.cuda(non_blocking=True),\n",
    "                    mask.cuda(non_blocking=True),\n",
    "                    grappa.cuda(non_blocking=True),\n",
    "                )\n",
    "                output = model.image_space_crop(output)\n",
    "                for i in range(output.shape[0]):\n",
    "                    reconstructions[fnames[i]][slices[i]] = output[i].cpu().numpy()\n",
    "        else:\n",
    "            for mask, kspace, target, maximum, fnames, slices in tqdm(dataloader):\n",
    "                output = model(\n",
    "                    kspace.cuda(non_blocking=True), mask.cuda(non_blocking=True)\n",
    "                )\n",
    "                output = model.image_space_crop(output)\n",
    "                for i in range(output.shape[0]):\n",
    "                    reconstructions[fnames[i]][slices[i]] = output[i].cpu().numpy()\n",
    "\n",
    "        for fname in reconstructions:\n",
    "            reconstructions[fname] = np.stack(\n",
    "                [\n",
    "                    reconstructions[fname][slice]\n",
    "                    for slice in sorted(reconstructions[fname])\n",
    "                ]\n",
    "            )\n",
    "        print(f\"Saving reconstructions of {phase} leaderboard...\")\n",
    "        save_reconstructions(reconstructions, Path(f\"{SAVE_DIR}/{phase}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 4c7f8191cbce4bc9bb9ffc5fe25e5913\n",
      "\n",
      "Leaderboard SSIM : 0.9656\n",
      "========== Details ==========\n",
      "Leaderboard SSIM (public): 0.9789\n",
      "Leaderboard SSIM (private): 0.9523\n"
     ]
    }
   ],
   "source": [
    "!sh leaderboard_eval.sh {HASH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
